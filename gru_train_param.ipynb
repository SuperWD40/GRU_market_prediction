{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Cuda version: 12.6\n",
      "Cuda device name: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "import tech_lib as tech\n",
    "import binance_api as binance\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import winsound\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "print(f'Cuda available: {torch.cuda.is_available()}')\n",
    "print(f'Cuda version: {torch.version.cuda}')\n",
    "print(f'Cuda device name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'lmxX1ymc6vGTQYkgUR194NeUxrhZQXM2xnf0rvjtQV4XxgP9xS9rawF6CvQRO2pw'\n",
    "api_secret = 'rNFCb6OYjktZ1O6yfpNy1EItYJGwOMe8rtW8salpdXDHaNQGdxJDwpqgXrysxjN7'\n",
    "\n",
    "ticker = 'BTCUSDT'\n",
    "interval = '1m'\n",
    "start_date = (2024, 6, 15, 0, 0, 0)\n",
    "end_date = (2025, 1, 15, 0, 0, 0)\n",
    "\n",
    "start_date_str = datetime(*start_date).strftime('%Y%m%d')\n",
    "end_date_str = datetime(*end_date).strftime('%Y%m%d')\n",
    "dataset_path = os.getcwd()+f'\\\\dataset\\\\{ticker}-{interval}-{start_date_str}-{end_date_str}.csv'\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    dataset = pd.read_csv(dataset_path, index_col='Open Time')\n",
    "else:\n",
    "    dataset = binance.historical_data(\n",
    "        api_key,\n",
    "        api_secret,\n",
    "        ticker,\n",
    "        interval,\n",
    "        start_date,\n",
    "        end_date\n",
    "    )\n",
    "    dataset = dataset.drop(['Ignore', 'Close Time'], axis=1)\n",
    "\n",
    "dataset.to_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des outputs\n",
    "dataset['Close_target'] = dataset['Close'].shift(-1)\n",
    "dataset['DirVar_target'] = pd.Series([1 if diff > 0 else 0 for diff in dataset['Close'].diff(1)], index=dataset.index, dtype=int).shift(-1)\n",
    "#dataset['Returns'] = np.log(dataset['Close'] / dataset['Close'].shift(1))\n",
    "#dataset['Returns_target'] = dataset.Returns - dataset.Returns.diff(-1)\n",
    "\n",
    "# Boucle pour calculer les indicateurs avec différentes fenêtres\n",
    "for window in range(30, 121, 30):\n",
    "    dataset[f'cmf_{window}'] = tech.cmf(high=dataset.High, low=dataset.Low, close=dataset.Close, volume=dataset.Volume, window=window)\n",
    "    dataset[f'rsi_{window}'] = tech.rsi(close=dataset.Close, window=window)\n",
    "    dataset[f'ma_{window}'] = tech.ma(close=dataset.Close, window=window)\n",
    "    dataset[f'ema_{window}'] = tech.ema(close=dataset.Close, window=window)\n",
    "    dataset[f'atr_{window}'] = tech.atr(high=dataset.High, low=dataset.Low, close=dataset.Close, window=window)\n",
    "    dataset[f'bollinger_{window}'] = tech.bollinger_band_width(close=dataset.Close, window=window, num_std=2)\n",
    "dataset['obv'] = tech.obv(dataset.Close, dataset.Volume)\n",
    "\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "---------- Launch Time: 2025-01-22 20:35:54 ---------- Progress: 0/166,693,920 ----------\n",
      "Epoch 1/5, Train Loss: 6,432,548,305.291228, Validation Loss: 30,053,709,295.213116, Time: 0:00:01.785168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 77\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Prétraitement des données\u001b[39;00m\n\u001b[0;32m     70\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mpreprocess(\n\u001b[0;32m     71\u001b[0m     train_size\u001b[38;5;241m=\u001b[39mtrain_size,\n\u001b[0;32m     72\u001b[0m     val_size\u001b[38;5;241m=\u001b[39mval_size, \n\u001b[0;32m     73\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size, \n\u001b[0;32m     74\u001b[0m     seq_size\u001b[38;5;241m=\u001b[39mseq_size\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m pipeline\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     79\u001b[0m pipeline\u001b[38;5;241m.\u001b[39msave(result_path)\n",
      "File \u001b[1;32mc:\\Users\\Matteo\\Documents\\GitHub local\\PadapiGRU\\gru_lib.py:129\u001b[0m, in \u001b[0;36mPipeline.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gru_lib import GRUModel, Pipeline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Définir les plages de valeurs pour les hyperparamètres\n",
    "period_size = 100000\n",
    "hidden_size = 8\n",
    "num_layers = 1\n",
    "dropout = 0.0\n",
    "lr = 0.1\n",
    "batch_size = 512\n",
    "epochs = 5\n",
    "num_workers = 4\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "seq_size = 30\n",
    "\n",
    "\n",
    "inputs = [\n",
    "    'Open', 'Close', 'High', 'Low', \n",
    "    'Volume', 'Number of Trades', 'Taker Buy Base Asset Volume',\n",
    "    'obv', 'cmf_30', 'ema_30', 'atr_30',\n",
    "    'rsi_30', 'ma_30', 'bollinger_30',\n",
    "]\n",
    "min_imputs = 6\n",
    "outputs = 'DirVar_target'\n",
    "\n",
    "result_path = os.getcwd()+f'\\\\train_result\\\\GRU-{ticker}-{interval}-inputs_selection.csv'\n",
    "\n",
    "# Générer toutes les combinaisons additives possibles des inputs\n",
    "input_combinations = [list(itertools.combinations(inputs, r)) for r in range(min_imputs, len(inputs) + 1)]\n",
    "input_combinations = [item for sublist in input_combinations for item in sublist]\n",
    "\n",
    "counter = 0\n",
    "for input_subset in input_combinations:\n",
    "    time_lauch = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'---------- Launch Time: {time_lauch:<10} ---------- Progress: {(counter):,}/{(len(input_combinations)):,} ----------')\n",
    "\n",
    "    # Garder la période étudiée\n",
    "    dataset_subset = dataset.iloc[period_size:]\n",
    "    dataset_subset = dataset_subset.dropna()\n",
    "\n",
    "    # Initialiser le modèle\n",
    "    model = GRUModel(\n",
    "        input_size=len(input_subset),\n",
    "        output_size=1,\n",
    "        hidden_size=hidden_size, \n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "\n",
    "    # Initialiser le pipeline\n",
    "    pipeline = Pipeline(\n",
    "        model=model, \n",
    "        dataset=dataset_subset,\n",
    "        inputs=list(input_subset),\n",
    "        outputs=outputs\n",
    "    )\n",
    "\n",
    "    # Définir les hyperparamètres\n",
    "    pipeline.hyper_param(\n",
    "        lr=lr, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # Prétraitement des données\n",
    "    pipeline.preprocess(\n",
    "        train_size=train_size,\n",
    "        val_size=val_size, \n",
    "        test_size=test_size, \n",
    "        seq_size=seq_size\n",
    "    )\n",
    "\n",
    "    pipeline.train()\n",
    "    pipeline.eval()\n",
    "    pipeline.save(result_path)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "---------- Launch Time: 2025-01-23 21:24:42 ---------- Progress: 0/1 ----------\n",
      "Epoch 1/50, Train Loss: 94,887.478733, Validation Loss: 439,859.753112, Time: 0:00:40.325395\n",
      "Epoch 2/50, Train Loss: 94,706.099791, Validation Loss: 439,018.954118, Time: 0:00:41.902652\n",
      "Epoch 3/50, Train Loss: 94,526.746401, Validation Loss: 438,187.544756, Time: 0:00:46.401106\n",
      "Epoch 4/50, Train Loss: 94,344.843422, Validation Loss: 437,344.316539, Time: 0:00:42.639538\n",
      "Epoch 5/50, Train Loss: 94,164.386883, Validation Loss: 436,507.793432, Time: 0:00:41.254528\n",
      "Epoch 6/50, Train Loss: 93,985.909821, Validation Loss: 435,680.446372, Time: 0:00:41.186472\n",
      "Epoch 7/50, Train Loss: 93,805.239788, Validation Loss: 434,842.933594, Time: 0:00:41.018807\n",
      "Epoch 8/50, Train Loss: 93,626.281350, Validation Loss: 434,013.355072, Time: 0:00:41.457772\n",
      "Epoch 9/50, Train Loss: 93,445.646509, Validation Loss: 433,176.005429, Time: 0:00:40.748548\n",
      "Epoch 10/50, Train Loss: 93,266.530650, Validation Loss: 432,345.697166, Time: 0:00:40.787396\n",
      "Epoch 11/50, Train Loss: 93,088.231161, Validation Loss: 431,519.173265, Time: 0:00:40.948462\n",
      "Epoch 12/50, Train Loss: 92,908.537934, Validation Loss: 430,686.188559, Time: 0:00:40.954805\n",
      "Epoch 13/50, Train Loss: 92,728.412006, Validation Loss: 429,851.198027, Time: 0:00:40.987952\n",
      "Epoch 14/50, Train Loss: 92,549.148166, Validation Loss: 429,020.203787, Time: 0:00:41.076947\n",
      "Epoch 15/50, Train Loss: 92,368.583052, Validation Loss: 428,183.177370, Time: 0:00:40.952640\n",
      "Epoch 16/50, Train Loss: 92,190.127071, Validation Loss: 427,355.928032, Time: 0:00:40.940028\n",
      "Epoch 17/50, Train Loss: 92,012.609703, Validation Loss: 426,533.029727, Time: 0:00:41.016979\n",
      "Epoch 18/50, Train Loss: 91,833.440614, Validation Loss: 425,702.474709, Time: 0:00:41.232390\n",
      "Epoch 19/50, Train Loss: 91,654.111946, Validation Loss: 424,871.179952, Time: 0:00:41.164413\n",
      "Epoch 20/50, Train Loss: 91,475.971764, Validation Loss: 424,045.394531, Time: 0:00:44.242402\n",
      "Epoch 21/50, Train Loss: 91,297.076125, Validation Loss: 423,216.107124, Time: 0:00:46.960409\n",
      "Epoch 22/50, Train Loss: 91,117.582324, Validation Loss: 422,384.046875, Time: 0:00:43.638199\n",
      "Epoch 23/50, Train Loss: 90,940.652894, Validation Loss: 421,563.874007, Time: 0:00:42.143886\n",
      "Epoch 24/50, Train Loss: 90,761.668162, Validation Loss: 420,734.173596, Time: 0:00:40.944455\n",
      "Epoch 25/50, Train Loss: 90,583.799403, Validation Loss: 419,909.646385, Time: 0:00:41.107618\n",
      "Epoch 26/50, Train Loss: 90,405.414162, Validation Loss: 419,082.724974, Time: 0:00:41.250206\n",
      "Epoch 27/50, Train Loss: 90,228.428288, Validation Loss: 418,262.290453, Time: 0:00:43.579937\n",
      "Epoch 28/50, Train Loss: 90,050.356233, Validation Loss: 417,436.820842, Time: 0:00:43.267658\n",
      "Epoch 29/50, Train Loss: 89,873.560058, Validation Loss: 416,617.265691, Time: 0:00:39.928738\n",
      "Epoch 30/50, Train Loss: 89,694.580810, Validation Loss: 415,787.590704, Time: 0:00:39.679290\n",
      "Epoch 31/50, Train Loss: 89,517.395952, Validation Loss: 414,966.233779, Time: 0:00:39.505621\n",
      "Epoch 32/50, Train Loss: 89,341.357832, Validation Loss: 414,150.192664, Time: 0:00:39.165264\n",
      "Epoch 33/50, Train Loss: 89,163.058187, Validation Loss: 413,323.668035, Time: 0:00:42.806251\n",
      "Epoch 34/50, Train Loss: 88,985.969378, Validation Loss: 412,502.756356, Time: 0:00:46.144024\n",
      "Epoch 35/50, Train Loss: 88,809.535878, Validation Loss: 411,684.882415, Time: 0:00:45.834962\n",
      "Epoch 36/50, Train Loss: 88,632.382355, Validation Loss: 410,863.670749, Time: 0:00:46.113705\n",
      "Epoch 37/50, Train Loss: 88,454.906179, Validation Loss: 410,040.963387, Time: 0:00:45.982395\n",
      "Epoch 38/50, Train Loss: 88,278.838280, Validation Loss: 409,224.784229, Time: 0:00:46.206347\n",
      "Epoch 39/50, Train Loss: 88,101.527308, Validation Loss: 408,402.842691, Time: 0:00:46.082792\n",
      "Epoch 40/50, Train Loss: 87,925.304288, Validation Loss: 407,585.944452, Time: 0:00:46.225755\n",
      "Epoch 41/50, Train Loss: 87,749.455353, Validation Loss: 406,770.780323, Time: 0:00:46.555735\n",
      "Epoch 42/50, Train Loss: 87,572.384484, Validation Loss: 405,949.951801, Time: 0:00:46.347182\n",
      "Epoch 43/50, Train Loss: 87,396.043204, Validation Loss: 405,132.505363, Time: 0:00:46.623878\n",
      "Epoch 44/50, Train Loss: 87,220.148766, Validation Loss: 404,317.130297, Time: 0:00:46.323010\n",
      "Epoch 45/50, Train Loss: 87,044.112132, Validation Loss: 403,501.096067, Time: 0:00:46.254632\n",
      "Epoch 46/50, Train Loss: 86,867.869330, Validation Loss: 402,684.106131, Time: 0:00:46.293346\n",
      "Epoch 47/50, Train Loss: 86,691.590165, Validation Loss: 401,866.947630, Time: 0:00:46.329654\n",
      "Epoch 48/50, Train Loss: 86,515.968721, Validation Loss: 401,052.838056, Time: 0:00:46.264812\n",
      "Epoch 49/50, Train Loss: 86,341.317013, Validation Loss: 400,243.223782, Time: 0:00:46.450720\n",
      "Epoch 50/50, Train Loss: 86,164.873886, Validation Loss: 399,425.305217, Time: 0:00:46.316756\n",
      "Time elapsed: 2161.5826\n",
      "Train Loss: 86,164.873886\n",
      "Val Loss: 399,425.305217\n",
      "Test Loss: 10,162,523.929688\n",
      "R^2 : -185.1901\n",
      "R^2 ajusté : -185.9383\n",
      "MAPE : 0.9058\n",
      "RMSE : 86,353.664522\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GRUModel' object has no attribute 'hidden_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     83\u001b[0m pipeline\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 84\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mloss(plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     87\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mpred(plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Matteo\\Documents\\GitHub local\\PadapiGRU\\gru_lib.py:235\u001b[0m, in \u001b[0;36mPipeline.save\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    229\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Construire le dictionnaire des résultats\u001b[39;00m\n\u001b[0;32m    232\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset size\u001b[39m\u001b[38;5;124m'\u001b[39m  : \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset),\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindow size\u001b[39m\u001b[38;5;124m'\u001b[39m   : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_size,\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHidden size\u001b[39m\u001b[38;5;124m'\u001b[39m   : \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m,\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum layers\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout\u001b[39m\u001b[38;5;124m'\u001b[39m       : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput size\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs),\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain size\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_size,\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal size\u001b[39m\u001b[38;5;124m'\u001b[39m      : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_size,\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest size\u001b[39m\u001b[38;5;124m'\u001b[39m     : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_size,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch size\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m        : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs,\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning rate\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr,\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss, \u001b[38;5;241m6\u001b[39m),\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m'\u001b[39m      : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loss, \u001b[38;5;241m6\u001b[39m),\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m     : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loss, \u001b[38;5;241m6\u001b[39m),\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m            : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr2, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2_bar\u001b[39m\u001b[38;5;124m'\u001b[39m        : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr2_bar, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m'\u001b[39m          : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmape, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m          : \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrmse, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining time\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_elapsed,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining device\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m       : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs,\n\u001b[0;32m    255\u001b[0m }\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Ajouter les entrées\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, input_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1930\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GRUModel' object has no attribute 'hidden_size'"
     ]
    }
   ],
   "source": [
    "from gru_lib import GRUModel, Pipeline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Définir les plages de valeurs pour les hyperparamètres\n",
    "param_grid = {\n",
    "    \"period_size\"   : [100000],\n",
    "    \"hidden_size\"   : [32],\n",
    "    \"num_layers\"    : [4],\n",
    "    \"dropout\"       : [0.1],\n",
    "    \"lr\"            : [0.01],\n",
    "    \"batch_size\"    : [128],\n",
    "    \"epochs\"        : [50],\n",
    "    \"num_workers\"   : [4],\n",
    "    \"delta\"         : [1],\n",
    "    \"weight_decay\"  : [1e-4],\n",
    "    \"train_size\"    : [0.7],\n",
    "    \"val_size\"      : [0.15],\n",
    "    \"test_size\"     : [0.15],\n",
    "    \"seq_size\"      : [60]\n",
    "}\n",
    "\n",
    "inputs = [\n",
    "    'High', 'Low', 'Open', 'Close',\n",
    "    'Volume', 'obv', 'cmf_90', 'ma_90'\n",
    "]\n",
    "outputs = 'Close_target'\n",
    "\n",
    "result_path = os.getcwd()+f'\\\\train_result\\\\GRU-{ticker}-{interval}-param_selection.csv'\n",
    "\n",
    "# Générer toutes les combinaisons possibles d'hyperparamètres\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "counter = 0\n",
    "for params in param_combinations:\n",
    "    time_lauch = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'---------- Launch Time: {time_lauch:<10} ---------- Progress: {(counter):,}/{(len(param_combinations)):,} ----------')\n",
    "\n",
    "    # Extraire les paramètres pour cette combinaison\n",
    "    hyperparams = dict(zip(param_grid.keys(), params))\n",
    "\n",
    "    # Garder la période étudiée\n",
    "    dataset_subset = dataset.iloc[-hyperparams[\"period_size\"]:]\n",
    "    dataset_subset = dataset_subset.dropna()\n",
    "\n",
    "    # Initialiser le modèle\n",
    "    model = GRUModel(\n",
    "        input_size=len(inputs),\n",
    "        output_size=1,\n",
    "        hidden_size=hyperparams[\"hidden_size\"], \n",
    "        num_layers=hyperparams[\"num_layers\"],\n",
    "        dropout=hyperparams[\"dropout\"]\n",
    "    )\n",
    "\n",
    "    # Initialiser le pipeline\n",
    "    pipeline = Pipeline(\n",
    "        model=model, \n",
    "        dataset=dataset_subset,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs\n",
    "    )\n",
    "\n",
    "    # Définir les hyperparamètres\n",
    "    pipeline.hyper_param(\n",
    "        lr=hyperparams[\"lr\"], \n",
    "        batch_size=hyperparams[\"batch_size\"], \n",
    "        epochs=hyperparams[\"epochs\"],\n",
    "        num_workers=hyperparams[\"num_workers\"],\n",
    "        delta=hyperparams[\"delta\"],\n",
    "        weight_decay=hyperparams[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # Prétraitement des données\n",
    "    pipeline.preprocess(\n",
    "        train_size=hyperparams[\"train_size\"],\n",
    "        val_size=hyperparams[\"val_size\"], \n",
    "        test_size=hyperparams[\"test_size\"], \n",
    "        seq_size=hyperparams[\"seq_size\"]\n",
    "    )\n",
    "\n",
    "    pipeline.train()\n",
    "    pipeline.eval()\n",
    "    pipeline.save(result_path)\n",
    "\n",
    "    pipeline.loss(plot=True)\n",
    "    pipeline.pred(plot=True)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    counter += 1\n",
    "\n",
    "winsound.Beep(1000, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
